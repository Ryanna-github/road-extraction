{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare different loss functions\n",
    "\n",
    "- We have versions of dice bce loss\n",
    "    - belongs to torch.nn.Module\n",
    "    - belongs to torch.autograd.Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dice_bce_loss(nn.Module):\n",
    "    def __init__(self, batch=True):\n",
    "        super(dice_bce_loss, self).__init__()\n",
    "        self.batch = batch\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        \n",
    "    def soft_dice_coeff(self, y_true, y_pred):\n",
    "        smooth = 0.0  # may change\n",
    "        if self.batch:\n",
    "            i = torch.sum(y_true)\n",
    "            j = torch.sum(y_pred)\n",
    "            intersection = torch.sum(y_true * y_pred)\n",
    "        else:\n",
    "            i = y_true.sum(1).sum(1).sum(1)\n",
    "            j = y_pred.sum(1).sum(1).sum(1)\n",
    "            intersection = (y_true * y_pred).sum(1).sum(1).sum(1)\n",
    "        score = (2. * intersection + smooth) / (i + j + smooth)\n",
    "        #score = (intersection + smooth) / (i + j - intersection + smooth)#iou\n",
    "        return score.mean()\n",
    "\n",
    "    def soft_dice_loss(self, y_true, y_pred):\n",
    "        loss = 1 - self.soft_dice_coeff(y_true, y_pred)\n",
    "        return loss\n",
    "        \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        a =  self.bce_loss(y_pred, y_true)\n",
    "        b =  self.soft_dice_loss(y_true, y_pred)\n",
    "        return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for individual examples\"\"\"\n",
    "\n",
    "    # 在进入 forward 之前，所有变量都会被转化为 tensor\n",
    "    def forward(self, input, target):\n",
    "        self.save_for_backward(input, target) # tensor 转化为变量保存到后续操作\n",
    "        eps = 0.0001\n",
    "        self.inter = torch.dot(input.view(-1), target.view(-1))\n",
    "        self.union = torch.sum(input) + torch.sum(target) + eps\n",
    "\n",
    "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
    "        return t\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    def backward(self, grad_output):\n",
    "        input, target = self.saved_variables\n",
    "        grad_input = grad_target = None\n",
    "\n",
    "        # 判断 input 是否需要求梯度\n",
    "        if self.needs_input_grad[0]:\n",
    "            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n",
    "                         / (self.union * self.union)\n",
    "        # 判断 target 是否需要求梯度\n",
    "        if self.needs_input_grad[1]:\n",
    "            grad_target = None\n",
    "\n",
    "        return grad_input, grad_target\n",
    "\n",
    "\n",
    "def dice_coeff(input, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    # 在合适的设备上初始化一个1*1零向量\n",
    "    # 同一个 batch 中 dice loss 取平均\n",
    "    s = torch.FloatTensor(1).cuda().zero_() if input.is_cuda else torch.FloatTensor(1).zero_()\n",
    "    for i, c in enumerate(zip(input, target)):\n",
    "        s = s + DiceCoeff().forward(c[0], c[1])\n",
    "    return s / (i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

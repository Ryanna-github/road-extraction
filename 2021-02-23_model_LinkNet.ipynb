{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Function\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "import data_loader\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE, OUTPUT_SIZE = 256, 256\n",
    "# root_path = 'D://Data/massachusetts-roads-dataset/'\n",
    "root_path = '/home/renyan/ossdata/massachusetts-roads-dataset/'\n",
    "road_path = root_path + \"tiff_select2_parts_16/\"\n",
    "\n",
    "DIR_CHECKPOINT = 'checkpoints/'\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCH_NUM = 20\n",
    "LR = 0.0002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkNet34(nn.Module):\n",
    "    def __init__(self, num_classes = 1):\n",
    "        super(LinkNet34, self).__init__()\n",
    "        self.nonlinearity = partial(F.relu,inplace=True)\n",
    "        self.n_classes = num_classes\n",
    "\n",
    "        filters = [64, 128, 256, 512]\n",
    "        resnet = models.resnet34(pretrained = True)\n",
    "        self.firstconv = resnet.conv1\n",
    "        self.firstbn = resnet.bn1\n",
    "        self.firstrelu = resnet.relu\n",
    "        self.firstmaxpool = resnet.maxpool\n",
    "        self.encoder1 = resnet.layer1\n",
    "        self.encoder2 = resnet.layer2\n",
    "        self.encoder3 = resnet.layer3\n",
    "        self.encoder4 = resnet.layer4\n",
    "\n",
    "        self.decoder4 = DecoderBlock(filters[3], filters[2])\n",
    "        self.decoder3 = DecoderBlock(filters[2], filters[1])\n",
    "        self.decoder2 = DecoderBlock(filters[1], filters[0])\n",
    "        self.decoder1 = DecoderBlock(filters[0], filters[0])\n",
    "\n",
    "        self.finaldeconv1 = nn.ConvTranspose2d(filters[0], 32, 3, stride=2)\n",
    "        self.finalrelu1 = self.nonlinearity\n",
    "        self.finalconv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.finalrelu2 = self.nonlinearity\n",
    "        self.finalconv3 = nn.Conv2d(32, num_classes, 2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.firstconv(x)\n",
    "        x = self.firstbn(x)\n",
    "        x = self.firstrelu(x)\n",
    "        x = self.firstmaxpool(x)\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.decoder4(e4) + e3\n",
    "        d3 = self.decoder3(d4) + e2\n",
    "        d2 = self.decoder2(d3) + e1\n",
    "        d1 = self.decoder1(d2)\n",
    "        out = self.finaldeconv1(d1)\n",
    "        out = self.finalrelu1(out)\n",
    "        out = self.finalconv2(out)\n",
    "        out = self.finalrelu2(out)\n",
    "        out = self.finalconv3(out)\n",
    "\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, n_filters):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        self.nonlinearity = partial(F.relu,inplace=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels // 4, 1)\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels // 4)\n",
    "        self.relu1 = self.nonlinearity\n",
    "\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels // 4, in_channels // 4, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(in_channels // 4)\n",
    "        self.relu2 = self.nonlinearity\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels // 4, n_filters, 1)\n",
    "        self.norm3 = nn.BatchNorm2d(n_filters)\n",
    "        self.relu3 = self.nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.relu3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tnet = LinkNet34().cuda()\n",
    "# summary(tnet, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dice_bce_loss(nn.Module):\n",
    "    def __init__(self, batch=True):\n",
    "        super(dice_bce_loss, self).__init__()\n",
    "        self.batch = batch\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        \n",
    "    def soft_dice_coeff(self, y_true, y_pred):\n",
    "        smooth = 0.0  # may change\n",
    "        if self.batch:\n",
    "            i = torch.sum(y_true)\n",
    "            j = torch.sum(y_pred)\n",
    "            intersection = torch.sum(y_true * y_pred)\n",
    "        else:\n",
    "            i = y_true.sum(1).sum(1).sum(1)\n",
    "            j = y_pred.sum(1).sum(1).sum(1)\n",
    "            intersection = (y_true * y_pred).sum(1).sum(1).sum(1)\n",
    "        score = (2. * intersection + smooth) / (i + j + smooth)\n",
    "        #score = (intersection + smooth) / (i + j - intersection + smooth)#iou\n",
    "        return score.mean()\n",
    "\n",
    "    def soft_dice_loss(self, y_true, y_pred):\n",
    "        loss = 1 - self.soft_dice_coeff(y_true, y_pred)\n",
    "        return loss\n",
    "        \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        a =  self.bce_loss(y_pred, y_true)\n",
    "        b =  self.soft_dice_loss(y_true, y_pred)\n",
    "        return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 7056 images\n",
      "Read 224 images\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_loader.RoadDataset(road_path, True, INPUT_SIZE, OUTPUT_SIZE)\n",
    "val_dataset = data_loader.RoadDataset(road_path, False, INPUT_SIZE, OUTPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle = False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for individual examples\"\"\"\n",
    "\n",
    "    # 在进入 forward 之前，所有变量都会被转化为 tensor\n",
    "    def forward(self, input, target):\n",
    "        self.save_for_backward(input, target) # tensor 转化为变量保存到后续操作\n",
    "        eps = 0.0001\n",
    "        self.inter = torch.dot(input.view(-1), target.view(-1))\n",
    "        self.union = torch.sum(input) + torch.sum(target) + eps\n",
    "\n",
    "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
    "        return t\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    def backward(self, grad_output):\n",
    "        input, target = self.saved_variables\n",
    "        grad_input = grad_target = None\n",
    "\n",
    "        # 判断 input 是否需要求梯度\n",
    "        if self.needs_input_grad[0]:\n",
    "            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n",
    "                         / (self.union * self.union)\n",
    "        # 判断 target 是否需要求梯度\n",
    "        if self.needs_input_grad[1]:\n",
    "            grad_target = None\n",
    "\n",
    "        return grad_input, grad_target\n",
    "\n",
    "\n",
    "def dice_coeff(input, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    # 在合适的设备上初始化一个1*1零向量\n",
    "    # 同一个 batch 中 dice loss 取平均\n",
    "    s = torch.FloatTensor(1).cuda().zero_() if input.is_cuda else torch.FloatTensor(1).zero_()\n",
    "    for i, c in enumerate(zip(input, target)):\n",
    "        s = s + DiceCoeff().forward(c[0], c[1])\n",
    "    return s / (i + 1)\n",
    "\n",
    "def eval_net(net, loader, device):\n",
    "    \"\"\"Evaluation without the densecrf with the dice coefficient\"\"\"\n",
    "    # 关闭 batchnorm 和 dropout\n",
    "    net.eval() # 仔细看\n",
    "    mask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
    "    n_val = len(loader)  # the number of batch\n",
    "    tot = 0\n",
    "\n",
    "    # 括号里设置文字输出信息\n",
    "#     with tqdm(total = n_val, desc='Validation round', unit='batch', leave = False) as pbar:\n",
    "        # 对于每个 batch\n",
    "    for batch in loader:\n",
    "        imgs, true_masks = batch[0], batch[1]\n",
    "        imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "        true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "        # 不需要追踪梯度变化，不需要进行反向传播，提升速度\n",
    "        with torch.no_grad():\n",
    "            # 得到模型预测结果\n",
    "            mask_pred = net(imgs)\n",
    "\n",
    "        # 不同类别预测结果损失累加\n",
    "        if net.n_classes > 1:\n",
    "            tot += F.cross_entropy(mask_pred, true_masks).item()\n",
    "        else:\n",
    "            pred = torch.sigmoid(mask_pred)\n",
    "            pred = (pred > 0.5).float()\n",
    "            tot += dice_coeff(pred, true_masks).item()\n",
    "#             pbar.update()\n",
    "\n",
    "    net.train()\n",
    "    return tot / n_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, device, train_dataset, val_dataset, epochs = EPOCH_NUM, lr = LR, save_cp = True,\n",
    "             batch_size = BATCH_SIZE):\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle = False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "    \n",
    "    # 每轮 evaluation 检验的 batch 个数\n",
    "    n_val = len(val_dataset)\n",
    "    # 每轮 train 检验的 batch 个数\n",
    "    n_train = len(train_dataset)\n",
    "\n",
    "    writer = SummaryWriter(comment=f'LR_{lr}_BS_{BATCH_SIZE}')\n",
    "    global_step = 0\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {lr}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_cp}\n",
    "        Device:          {device.type}\n",
    "    ''')\n",
    "#     换 SGD，图像用 SGD Adam，收敛速度而非效果\n",
    "#     optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "#     optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "    optimizer = torch.optim.Adam(params = net.parameters(), lr = lr)\n",
    "    # 在发现loss不再降低或者acc不再提高之后，降低学习率。patience 含义：不再减小（或增大）的累计次数\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.n_classes > 1 else 'max', patience=2)\n",
    "    \n",
    "    if net.n_classes > 1:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        print(net.firstconv.weight[0,0,0])\n",
    "\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total = n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                \n",
    "                imgs = batch[0]\n",
    "                true_masks = batch[1]\n",
    "\n",
    "                imgs = imgs.to(device = device, dtype = torch.float32)\n",
    "                mask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
    "                true_masks = true_masks.to(device = device, dtype = mask_type) # 01\n",
    "\n",
    "                masks_pred = net(imgs)\n",
    "                loss = criterion(masks_pred, true_masks)\n",
    "                epoch_loss += loss.item()\n",
    "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # 对于每个 batch 都要更新一次参数空间\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # 防止梯度爆炸，设置梯度截断\n",
    "                nn.utils.clip_grad_value_(net.parameters(), 1)\n",
    "                optimizer.step()\n",
    "\n",
    "                # 每个 batch 结束更新一次进度条，迭代器内部计数器累加 batch 的大小\n",
    "                pbar.update(imgs.shape[0])\n",
    "                global_step += 1\n",
    "                \n",
    "                # 在 tensorboard 中记录一次\n",
    "                if global_step % (n_train // (10 * batch_size) + 1) == 0:\n",
    "                    for tag, value in net.named_parameters():\n",
    "                        tag = tag.replace('.', '/')\n",
    "                        writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)\n",
    "                        writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_step)\n",
    "                    val_score = eval_net(net, val_loader, device)\n",
    "                    scheduler.step(val_score)\n",
    "                    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "\n",
    "                    if net.n_classes > 1:\n",
    "                        logging.info('Validation cross entropy: {}'.format(val_score))\n",
    "                        writer.add_scalar('Loss/test', val_score, global_step)\n",
    "                    else:\n",
    "                        logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
    "                        writer.add_scalar('Dice/test', val_score, global_step)\n",
    "\n",
    "                    writer.add_images('images', imgs, global_step)\n",
    "                    if net.n_classes == 1:\n",
    "                        writer.add_images('masks/true', true_masks, global_step)\n",
    "                        writer.add_images('masks/pred_0.5', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
    "                        writer.add_images('masks/pred_0.4', torch.sigmoid(masks_pred) > 0.4, global_step)\n",
    "                        writer.add_images('masks/pred_0.3', torch.sigmoid(masks_pred) > 0.3, global_step)\n",
    "                        writer.add_images('masks/pred_0.2', torch.sigmoid(masks_pred) > 0.2, global_step)\n",
    "                        writer.add_images('masks/pred_0.1', torch.sigmoid(masks_pred) > 0.1, global_step)\n",
    "\n",
    "        if save_cp:\n",
    "            try:\n",
    "                os.mkdir(DIR_CHECKPOINT)\n",
    "                logging.info('Created checkpoint directory')\n",
    "            except OSError:\n",
    "                pass\n",
    "            torch.save(net.state_dict(),\n",
    "                       DIR_CHECKPOINT + f'linknet_epoch{epoch + 1}.pth')\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved.')\n",
    "            if os.path.exists(DIR_CHECKPOINT + f'linknet_epoch{epoch - 4}.pth') & (epoch - 4)//10 != 0:\n",
    "                os.remove(DIR_CHECKPOINT + f'linknet_epoch{epoch - 4}.pth')\n",
    "                logging.info(f'Checkpoint {epoch - 4} deleted.')\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = LinkNet34().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tag, value in net.named_parameters():\n",
    "#     print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00541094, -0.00690917,  0.00788385,  0.03791069,  0.04907195,\n",
      "         0.03065980,  0.02539830], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 7056/7056 [25:46<00:00,  4.56img/s, loss (batch)=0.666]  \n",
      "Epoch 2/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00297228, -0.00722372,  0.01236094,  0.04059726,  0.04802738,\n",
      "         0.03082071,  0.02499680], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20:  49%|████▉     | 3448/7056 [10:51<09:20,  6.44img/s, loss (batch)=0.674]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 3/20: 100%|██████████| 7056/7056 [21:28<00:00,  5.47img/s, loss (batch)=0.665]  \n",
      "Epoch 4/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00375490, -0.00664559,  0.01287009,  0.04137861,  0.04862520,\n",
      "         0.03144569,  0.02572738], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20:  50%|████▉     | 3504/7056 [10:53<08:33,  6.92img/s, loss (batch)=0.677]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 5/20: 100%|██████████| 7056/7056 [22:32<00:00,  5.22img/s, loss (batch)=0.665]  \n",
      "Epoch 6/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00375545, -0.00664505,  0.01287069,  0.04137880,  0.04862544,\n",
      "         0.03144589,  0.02572775], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20:  34%|███▎      | 2372/7056 [07:33<11:38,  6.71img/s, loss (batch)=0.669]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 7/20: 100%|██████████| 7056/7056 [21:27<00:00,  5.48img/s, loss (batch)=0.665]  \n",
      "Epoch 8/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00375600, -0.00664450,  0.01287129,  0.04137898,  0.04862567,\n",
      "         0.03144610,  0.02572812], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20:  47%|████▋     | 3324/7056 [10:02<08:12,  7.57img/s, loss (batch)=0.677]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 9/20: 100%|██████████| 7056/7056 [21:29<00:00,  5.47img/s, loss (batch)=0.665]  \n",
      "Epoch 10/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00375655, -0.00664395,  0.01287189,  0.04137917,  0.04862590,\n",
      "         0.03144631,  0.02572850], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 7056/7056 [24:25<00:00,  4.81img/s, loss (batch)=0.665]  \n",
      "Epoch 11/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00375683, -0.00664368,  0.01287219,  0.04137926,  0.04862601,\n",
      "         0.03144642,  0.02572869], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 7056/7056 [22:30<00:00,  5.23img/s, loss (batch)=0.665]  \n",
      "Epoch 12/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00375710, -0.00664341,  0.01287249,  0.04137935,  0.04862613,\n",
      "         0.03144652,  0.02572887], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 7056/7056 [22:06<00:00,  5.32img/s, loss (batch)=0.665]  \n",
      "Epoch 13/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00375738, -0.00664313,  0.01287279,  0.04137945,  0.04862624,\n",
      "         0.03144662,  0.02572906], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 7056/7056 [21:28<00:00,  5.48img/s, loss (batch)=0.665]  \n",
      "Epoch 14/20:   0%|          | 0/7056 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.00375765, -0.00664286,  0.01287309,  0.04137954,  0.04862636,\n",
      "         0.03144673,  0.02572925], device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20:  53%|█████▎    | 3772/7056 [11:38<07:51,  6.97img/s, loss (batch)=0.641]  "
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=8)\n",
    "train_net(net, device, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

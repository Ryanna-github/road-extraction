{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Model in the Real World\n",
    "\n",
    "- Use data of GF satallite\n",
    "- Test if out trained model (trained on massachusetts-roads-dataset) can do the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from models import DLinkNet34, LinkNet34, FarSegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_SAVE_PATH = 'predict_result/mid_report/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_improve(p):\n",
    "    p.xticks([])\n",
    "    p.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/renyan/ossdata/gf-yunnan/IMG_0336.JPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "img_part = img[0:1500,0:1500] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize([256, 256], 0), transforms.ToTensor(),])\n",
    "img_part = transform(Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = LinkNet34.LinkNet34().to(device)\n",
    "net.load_state_dict(torch.load('checkpoints/v2_linknet34_re_epoch20.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_part.permute(1, 2, 0))\n",
    "plt_improve(plt)\n",
    "# plt.savefig(FIG_SAVE_PATH + 'img_gf_1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(img_part.unsqueeze(dim=0).to(device))\n",
    "pred = (torch.sigmoid(pred).squeeze(0) > 0.51).type(torch.float32)\n",
    "pred1 = torch.cat([pred]*3).permute(1, 2, 0)\n",
    "plt.imshow(pred1.cpu())\n",
    "plt_improve(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DLinkNet34.DLinkNet34().to(device)\n",
    "net.load_state_dict(torch.load('checkpoints/v2_dlinknet34_re_epoch20.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(img_part.unsqueeze(dim=0).to(device))\n",
    "pred = (torch.sigmoid(pred).squeeze(0) > 0.51).type(torch.float32)\n",
    "pred2 = torch.cat([pred]*3).permute(1, 2, 0)\n",
    "plt.imshow(pred2.cpu())\n",
    "plt_improve(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FarSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = FarSegNet.FarSegNet().to(device)\n",
    "net.eval()\n",
    "net.load_state_dict(torch.load('checkpoints/' + 'v2_farseg_epoch100.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_part.unsqueeze(dim=0).to(device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, preds = net(img_part.unsqueeze(dim=0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (probs > 0.2).float()\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.cat([pred.squeeze().unsqueeze(dim=0)]*3).permute(1, 2, 0).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.cat([probs.squeeze().unsqueeze(dim=0)]*3).permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(probs.flatten().detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(probs.squeeze().cpu().detach().numpy()*5)\n",
    "plt_improve(plt)\n",
    "plt.savefig(FIG_SAVE_PATH + 'pred_gf_1_channel1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.cat([probs.squeeze(0)]*3).permute(1, 2, 0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(utils.change_tensor_to_plot(tmp))\n",
    "plt_improve(plt)\n",
    "# plt.savefig(FIG_SAVE_PATH + 'pred_gf_1_channel3.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtmp = (tmp > 0.3).astype(float)\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "erorsion_img = cv2.erode(predtmp, kernel, iterations=1)\n",
    "plt.imshow(erorsion_img)\n",
    "plt_improve(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

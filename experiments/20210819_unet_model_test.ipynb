{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frame import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture/blob/main/PyTorch/unet.py\n",
    "\"\"\" Convolutional block:\n",
    "    It follows a two 3x3 convolutional layer, each followed by a batch normalization and a relu activation.\n",
    "\"\"\"\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\"\"\" Encoder block:\n",
    "    It consists of an conv_block followed by a max pooling.\n",
    "    Here the number of filters doubles and the height and width half after every block.\n",
    "\"\"\"\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "\n",
    "        return x, p\n",
    "\n",
    "\"\"\" Decoder block:\n",
    "    The decoder block begins with a transpose convolution, followed by a concatenation with the skip\n",
    "    connection from the encoder block. Next comes the conv_block.\n",
    "    Here the number filters decreases by half and the height and width doubles.\n",
    "\"\"\"\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c+out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(3, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.b = conv_block(512, 1024)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        b = self.b(p4)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        outputs = self.outputs(d4)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn((2, 3, 512, 512)).to(device)\n",
    "model = unet().to(device)\n",
    "y = model(inputs)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "        conv_block-7         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-8         [-1, 64, 128, 128]               0\n",
      "     encoder_block-9  [[-1, 64, 256, 256], [-1, 64, 128, 128]]               0\n",
      "           Conv2d-10        [-1, 128, 128, 128]          73,856\n",
      "      BatchNorm2d-11        [-1, 128, 128, 128]             256\n",
      "             ReLU-12        [-1, 128, 128, 128]               0\n",
      "           Conv2d-13        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-14        [-1, 128, 128, 128]             256\n",
      "             ReLU-15        [-1, 128, 128, 128]               0\n",
      "       conv_block-16        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-17          [-1, 128, 64, 64]               0\n",
      "    encoder_block-18  [[-1, 128, 128, 128], [-1, 128, 64, 64]]               0\n",
      "           Conv2d-19          [-1, 256, 64, 64]         295,168\n",
      "      BatchNorm2d-20          [-1, 256, 64, 64]             512\n",
      "             ReLU-21          [-1, 256, 64, 64]               0\n",
      "           Conv2d-22          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-23          [-1, 256, 64, 64]             512\n",
      "             ReLU-24          [-1, 256, 64, 64]               0\n",
      "       conv_block-25          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-26          [-1, 256, 32, 32]               0\n",
      "    encoder_block-27  [[-1, 256, 64, 64], [-1, 256, 32, 32]]               0\n",
      "           Conv2d-28          [-1, 512, 32, 32]       1,180,160\n",
      "      BatchNorm2d-29          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-30          [-1, 512, 32, 32]               0\n",
      "           Conv2d-31          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-33          [-1, 512, 32, 32]               0\n",
      "       conv_block-34          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-35          [-1, 512, 16, 16]               0\n",
      "    encoder_block-36  [[-1, 512, 32, 32], [-1, 512, 16, 16]]               0\n",
      "           Conv2d-37         [-1, 1024, 16, 16]       4,719,616\n",
      "      BatchNorm2d-38         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-39         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-40         [-1, 1024, 16, 16]       9,438,208\n",
      "      BatchNorm2d-41         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-42         [-1, 1024, 16, 16]               0\n",
      "       conv_block-43         [-1, 1024, 16, 16]               0\n",
      "  ConvTranspose2d-44          [-1, 512, 32, 32]       2,097,664\n",
      "           Conv2d-45          [-1, 512, 32, 32]       4,719,104\n",
      "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-47          [-1, 512, 32, 32]               0\n",
      "           Conv2d-48          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-49          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-50          [-1, 512, 32, 32]               0\n",
      "       conv_block-51          [-1, 512, 32, 32]               0\n",
      "    decoder_block-52          [-1, 512, 32, 32]               0\n",
      "  ConvTranspose2d-53          [-1, 256, 64, 64]         524,544\n",
      "           Conv2d-54          [-1, 256, 64, 64]       1,179,904\n",
      "      BatchNorm2d-55          [-1, 256, 64, 64]             512\n",
      "             ReLU-56          [-1, 256, 64, 64]               0\n",
      "           Conv2d-57          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-58          [-1, 256, 64, 64]             512\n",
      "             ReLU-59          [-1, 256, 64, 64]               0\n",
      "       conv_block-60          [-1, 256, 64, 64]               0\n",
      "    decoder_block-61          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-62        [-1, 128, 128, 128]         131,200\n",
      "           Conv2d-63        [-1, 128, 128, 128]         295,040\n",
      "      BatchNorm2d-64        [-1, 128, 128, 128]             256\n",
      "             ReLU-65        [-1, 128, 128, 128]               0\n",
      "           Conv2d-66        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-67        [-1, 128, 128, 128]             256\n",
      "             ReLU-68        [-1, 128, 128, 128]               0\n",
      "       conv_block-69        [-1, 128, 128, 128]               0\n",
      "    decoder_block-70        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-71         [-1, 64, 256, 256]          32,832\n",
      "           Conv2d-72         [-1, 64, 256, 256]          73,792\n",
      "      BatchNorm2d-73         [-1, 64, 256, 256]             128\n",
      "             ReLU-74         [-1, 64, 256, 256]               0\n",
      "           Conv2d-75         [-1, 64, 256, 256]          36,928\n",
      "      BatchNorm2d-76         [-1, 64, 256, 256]             128\n",
      "             ReLU-77         [-1, 64, 256, 256]               0\n",
      "       conv_block-78         [-1, 64, 256, 256]               0\n",
      "    decoder_block-79         [-1, 64, 256, 256]               0\n",
      "           Conv2d-80          [-1, 1, 256, 256]              65\n",
      "================================================================\n",
      "Total params: 31,043,521\n",
      "Trainable params: 31,043,521\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 44563490.50\n",
      "Params size (MB): 118.42\n",
      "Estimated Total Size (MB): 44563609.67\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
